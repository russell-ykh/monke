{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score, ConfusionMatrixDisplay\n",
    "import monke_features as mf\n",
    "import monke_classify as mc\n",
    "import monke_io as mio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KOI\n",
    "names_koi = [\"koi_apr11\", \"koi_apr17\", \"koi_apr25\", \"koi_apr25_3\", \"koi_apr25_4\", \"koi_apr25_5\", \"koi_apr25_6\"]\n",
    "\n",
    "pose_data_koi = mio.read_poses(names_koi)\n",
    "tremors_raw = mio.read_tremors_multi(names_koi)\n",
    "labels_koi = {}\n",
    "\n",
    "for name in tremors_raw:\n",
    "    labels_koi[name] = mf.generate_labelled_frames(pose_data_koi[name], tremors_raw[name])\n",
    "\n",
    "# BOBA\n",
    "names_boba = [\"boba_apr11\", \"boba_apr21\", \"boba_apr21_2\", \"boba_apr25\", \"boba_apr25_2\"]\n",
    "\n",
    "pose_data_boba = mio.read_poses(names_boba)\n",
    "tremors_raw = mio.read_tremors_multi(names_boba)\n",
    "labels_boba = {}\n",
    "\n",
    "for name in tremors_raw:\n",
    "    labels_boba[name] = mf.generate_labelled_frames(pose_data_boba[name], tremors_raw[name])\n",
    "\n",
    "# BANDUNG\n",
    "names_bandung = [\"bandung_mar27\", \"bandung_mar27_2\", \"bandung_mar27_3\", \"bandung_may19_2\"]\n",
    "\n",
    "pose_data_bandung = mio.read_poses(names_bandung)\n",
    "tremors_raw = mio.read_tremors_multi(names_bandung)\n",
    "labels_bandung = {}\n",
    "\n",
    "for name in tremors_raw:\n",
    "    labels_bandung[name] = mf.generate_labelled_frames(pose_data_bandung[name], tremors_raw[name])\n",
    "\n",
    "# HORLICKS\n",
    "names_horlicks = [\"horlicks_apr12\", \"horlicks_may2\", \"horlicks_jun16\"]\n",
    "\n",
    "pose_data_horlicks = mio.read_poses(names_horlicks)\n",
    "tremors_raw = mio.read_tremors_multi(names_horlicks)\n",
    "labels_horlicks = {}\n",
    "\n",
    "for name in tremors_raw:\n",
    "    labels_horlicks[name] = mf.generate_labelled_frames(pose_data_horlicks[name], tremors_raw[name])\n",
    "    \n",
    "# BRIYANI\n",
    "names_briyani = [\"briyani_apr12\", \"briyani_may19\", \"briyani_jun16\"]\n",
    "\n",
    "pose_data_briyani = mio.read_poses(names_briyani)\n",
    "tremors_raw = mio.read_tremors_multi(names_briyani)\n",
    "labels_briyani = {}\n",
    "\n",
    "for name in tremors_raw:\n",
    "    labels_briyani[name] = mf.generate_labelled_frames(pose_data_briyani[name], tremors_raw[name])\n",
    "    \n",
    "# TUTU KUEH\n",
    "names_tutukueh = [\"tutukueh_apr21\", \"tutukueh_may2\", \"tutukueh_jun15\"]\n",
    "\n",
    "pose_data_tutukueh = mio.read_poses(names_tutukueh)\n",
    "tremors_raw = mio.read_tremors_multi(names_tutukueh)\n",
    "labels_tutukueh = {}\n",
    "\n",
    "for name in tremors_raw:\n",
    "    labels_tutukueh[name] = mf.generate_labelled_frames(pose_data_tutukueh[name], tremors_raw[name])\n",
    "\n",
    "# ALL\n",
    "names_all = {\"koi\":names_koi, \"boba\":names_boba, \"bandung\":names_bandung, \n",
    "             \"horlicks\":names_horlicks, \"briyani\":names_briyani, \"tutukueh\":names_tutukueh}\n",
    "pose_data_all = {\"koi\":pose_data_koi, \"boba\":pose_data_boba, \"bandung\":pose_data_bandung, \n",
    "             \"horlicks\":pose_data_horlicks, \"briyani\":pose_data_briyani, \"tutukueh\":pose_data_tutukueh}\n",
    "labels_all = {\"koi\":labels_koi, \"boba\":labels_boba, \"bandung\":labels_bandung, \n",
    "             \"horlicks\":labels_horlicks, \"briyani\":labels_briyani, \"tutukueh\":labels_tutukueh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train_test_data(pose_data, labels, train_names, test_names=None, weights=None, test_size=0.2):\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "\n",
    "    if weights is not None:\n",
    "        training_weights = []\n",
    "\n",
    "    testing_data = {}\n",
    "    testing_labels = {}\n",
    "\n",
    "    for name in train_names:\n",
    "        pose_train = pose_data[name]\n",
    "        labels_train = labels[name]\n",
    "\n",
    "        if weights is not None:\n",
    "            weights_train = weights[name]\n",
    "            X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(pose_train, labels_train, weights_train, test_size=test_size)\n",
    "            training_weights.append(z_train)\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(pose_train, labels_train, test_size=test_size)\n",
    "\n",
    "        training_data.append(X_train)\n",
    "        training_labels.append(y_train)\n",
    "\n",
    "        if test_names is not None:\n",
    "            if name in test_names:\n",
    "                testing_data[name] = X_test\n",
    "                testing_labels[name] = y_test\n",
    "        else:\n",
    "            testing_data[name] = X_test\n",
    "            testing_labels[name] = y_test\n",
    "        \n",
    "    if(len(training_data) > 1):\n",
    "        training_data = np.concatenate(training_data)\n",
    "        training_labels = np.concatenate(training_labels)\n",
    "        if weights is not None:\n",
    "            training_weights = np.concatenate(training_weights)\n",
    "    else:\n",
    "        training_data = training_data[0]\n",
    "        training_labels = training_labels[0]\n",
    "        if weights is not None:\n",
    "            training_weights = training_weights[0]\n",
    "\n",
    "    if weights is None:\n",
    "        return training_data, testing_data, training_labels, testing_labels\n",
    "    else:\n",
    "        return training_data, testing_data, training_labels, testing_labels, training_weights\n",
    "\n",
    "def prep_multi_train_test_data(pose_data, labels, train_names, test_names=None, weights=None, test_size=0.2):\n",
    "    training_data = {}\n",
    "    training_labels = {}\n",
    "\n",
    "    if weights is not None:\n",
    "        training_weights = {}\n",
    "\n",
    "    testing_data = {}\n",
    "    testing_labels = {}\n",
    "\n",
    "    for name in train_names:\n",
    "        pose_train = pose_data[name]\n",
    "        labels_train = labels[name]\n",
    "\n",
    "        if weights is not None:\n",
    "            weights_train = weights[name]\n",
    "            X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(pose_train, labels_train, weights_train, test_size=test_size)\n",
    "            training_weights[name] = z_train\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(pose_train, labels_train, test_size=test_size)\n",
    "\n",
    "        training_data[name] = X_train\n",
    "        training_labels[name] = y_train\n",
    "        \n",
    "        if test_names is not None:\n",
    "            if name in test_names:\n",
    "                testing_data[name] = X_test\n",
    "                testing_labels[name] = y_test\n",
    "        else:\n",
    "            testing_data[name] = X_test\n",
    "            testing_labels[name] = y_test\n",
    "\n",
    "    if weights is None:\n",
    "        return training_data, testing_data, training_labels, testing_labels\n",
    "    else:\n",
    "        return training_data, testing_data, training_labels, testing_labels, training_weights\n",
    "\n",
    "def process_data(pose_data, labels, process):\n",
    "    processed_data = {}\n",
    "    processed_labels = {}\n",
    "\n",
    "    for name in pose_data:\n",
    "        processed_data[name] = process(pose_data[name])\n",
    "        processed_labels[name] = labels[name][:processed_data[name].shape[0]]\n",
    "    \n",
    "    return processed_data, processed_labels\n",
    "\n",
    "def test_classify(clf, test_data, test_labels):\n",
    "    predicted_labels = clf.predict(test_data)\n",
    "    mcc = matthews_corrcoef(test_labels, predicted_labels)\n",
    "    f1 = f1_score(test_labels, predicted_labels)\n",
    "    acc = accuracy_score(test_labels, predicted_labels)\n",
    "    return {\"predictions\":predicted_labels, \"mcc\":mcc, \"f1\":f1, \"accuracy\":acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18936\n",
      "18306\n",
      "20458\n",
      "18604\n",
      "2355\n",
      "21240\n",
      "1898\n"
     ]
    }
   ],
   "source": [
    "process = lambda x : mf.changes_in_changes(mf.vel(x), 10, 0.1)\n",
    "\n",
    "processed_koi_data, processed_koi_labels = process_data(pose_data_koi, labels_koi, process)\n",
    "# training_data, testing_data, training_labels, testing_labels = prep_multi_train_test_data(processed_data, processed_labels, names_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Test on Other Koi Video (koi_apr11), 10 minutes and 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1887"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_koi_data['koi_apr25_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_1_1 = [\"koi_apr17\", \"koi_apr25\", \"koi_apr25_3\", \"koi_apr25_4\", \"koi_apr25_5\", \"koi_apr25_6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_pose_data_1_1 = {}\n",
    "combined_train_labels_1_1 = {}\n",
    "all_train_pose_data_1_1 = np.empty((0,51))\n",
    "all_train_labels_1_1 = []\n",
    "for vid in combined_train_1_1:\n",
    "    all_train_pose_data_1_1 = np.concatenate((all_train_pose_data_1_1, processed_koi_data[vid]))\n",
    "    all_train_labels_1_1 = np.concatenate((all_train_labels_1_1, processed_koi_labels[vid]))\n",
    "temp = np.column_stack((all_train_pose_data_1_1, all_train_labels_1_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82795"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## HIDE FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_and_take_out(data):\n",
    "    # Calculate 20% of the total data length\n",
    "    twenty_percent = int(len(data) * 0.20)\n",
    "    fourty_percent = int(len(data) * 0.40)\n",
    "    sixty_percent = int(len(data) * 0.60)\n",
    "    eighty_percent = int(len(data) * 0.80)\n",
    "    one_hundert_percent = len(data)\n",
    "    \n",
    "    # Randomly select 20% of the data\n",
    "    sampled_data_20 = np.random.choice(data.shape[0], size=twenty_percent, replace=False)\n",
    "    sampled_data_40 = np.random.choice(data.shape[0], size=fourty_percent, replace=False)\n",
    "    sampled_data_60 = np.random.choice(data.shape[0], size=sixty_percent, replace=False)\n",
    "    sampled_data_80 = np.random.choice(data.shape[0], size=eighty_percent, replace=False)\n",
    "    sampled_data_100 = np.random.choice(data.shape[0], size=one_hundert_percent, replace=False)\n",
    "    \n",
    "    # Pool the remaining data\n",
    "    sampled_data = [sampled_data_20, sampled_data_40, sampled_data_60, sampled_data_80, sampled_data_100]\n",
    "    \n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taken out data (20%): [array([73096, 13760, 29222, ..., 35567, 45133, 39220]), array([37273, 19991, 77341, ..., 39484, 72439,  7955]), array([56236, 58508, 59804, ..., 59970, 67834, 13023]), array([23246, 13630, 36162, ..., 63960, 28102, 30919]), array([76850,  8104, 63894, ..., 78254, 67084, 38515])]\n"
     ]
    }
   ],
   "source": [
    "taken_out = pool_and_take_out(temp)\n",
    "print(\"Taken out data (20%):\", taken_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16559"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(taken_out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_1 = []\n",
    "\n",
    "for i in range(1,5):\n",
    "    combos = itertools.combinations(train_names_6c, i)\n",
    "\n",
    "    results_1_1.append({})\n",
    "\n",
    "    for train_combo in combos:\n",
    "        results_1_1[i-1][train_combo] = []\n",
    "        for _ in range(runs[i-1]):\n",
    "            training_data, test_data, training_labels, test_labels = prep_train_test_data(data_6c, labels_6c, combined_train_1_1, test_names=test_names_6c)\n",
    "            clf.fit(training_data, training_labels)\n",
    "            results_1_1[i-1][train_combo].append(test_classify(clf, np.concatenate([test_data[n] for n in test_data]), np.concatenate([test_labels[m] for m in test_labels])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names_1_1 = ['100per_1_1', '20per_1_1']\n",
    "train_names_1_1 = [\"20_1_1\", \"40_1_1\", \"60_1_1\", \"80_1_1\", \"100_1_1\"]\n",
    "\n",
    "clf = RandomForestClassifier(class_weight=\"balanced_subsample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_1 = []\n",
    "\n",
    "for i in range(1,6)\n",
    "    results_1_1[i] = []\n",
    "    training_data, test_data, training_labels, test_labels = prep_train_test_data(processed_koi_data, processed_koi_labels, train_combo, test_names=test_names_6c)\n",
    "    clf.fit(training_data, training_labels)\n",
    "    results_1_1[i].append(test_classify(clf, np.concatenate([test_data[n] for n in test_data]), np.concatenate([test_labels[m] for m in test_labels])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mccs_6c = []\n",
    "set_size = 1\n",
    "\n",
    "for set in results_6c:\n",
    "    mccs_6c.append([])\n",
    "    for combo in set:\n",
    "        for trial in set[combo]:\n",
    "            mccs_6c[set_size - 1].append(trial[\"mcc\"])\n",
    "    set_size += 1\n",
    "\n",
    "avg_mcc_6c = np.mean(mccs_6c, axis=1)\n",
    "variance_6c = np.var(mccs_6c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = list(range(1, len(variance_6c)+1))\n",
    "plt.bar(xticks, variance_6c)\n",
    "plt.title(\"Variance in MCC of Predictions of Koi April 25 (4) and Koi April 25 (6)\")\n",
    "plt.xlabel(\"Number of Training Datasets\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.xticks(xticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(xticks, avg_mcc_6c)\n",
    "plt.title(\"Average MCC of Predictions of Koi April 25 (4) and Koi April 25 (6)\")\n",
    "plt.xlabel(\"Number of Training Datasets\")\n",
    "plt.ylabel(\"MCC\")\n",
    "plt.xticks(xticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names_6c = [\"koi_apr25_4\", \"koi_apr25_6\"]\n",
    "train_names_6c = [\"koi_apr11\", \"koi_apr17\", \"koi_apr25\", \"koi_apr25_3\"]\n",
    "\n",
    "process = lambda x : mf.changes_in_changes(mf.vel(x), 10, 0.1)\n",
    "data_6c, labels_6c = process_data(pose_data_koi, labels_koi, process)\n",
    "\n",
    "runs = [3, 2, 3, 12]\n",
    "clf = RandomForestClassifier(class_weight=\"balanced_subsample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_6c = []\n",
    "\n",
    "for i in range(1,5):\n",
    "    combos = itertools.combinations(train_names_6c, i)\n",
    "\n",
    "    results_6c.append({})\n",
    "\n",
    "    for train_combo in combos:\n",
    "        results_6c[i-1][train_combo] = []\n",
    "        for _ in range(runs[i-1]):\n",
    "            training_data, test_data, training_labels, test_labels = prep_train_test_data(data_6c, labels_6c, train_combo, test_names=test_names_6c)\n",
    "            clf.fit(training_data, training_labels)\n",
    "            results_6c[i-1][train_combo].append(test_classify(clf, np.concatenate([test_data[n] for n in test_data]), np.concatenate([test_labels[m] for m in test_labels])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mccs_6c = []\n",
    "set_size = 1\n",
    "\n",
    "for set in results_6c:\n",
    "    mccs_6c.append([])\n",
    "    for combo in set:\n",
    "        for trial in set[combo]:\n",
    "            mccs_6c[set_size - 1].append(trial[\"mcc\"])\n",
    "    set_size += 1\n",
    "\n",
    "avg_mcc_6c = np.mean(mccs_6c, axis=1)\n",
    "variance_6c = np.var(mccs_6c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(xticks, avg_mcc_6c)\n",
    "plt.title(\"Average MCC of Predictions of Koi April 25 (4) and Koi April 25 (6)\")\n",
    "plt.xlabel(\"Number of Training Datasets\")\n",
    "plt.ylabel(\"MCC\")\n",
    "plt.xticks(xticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
